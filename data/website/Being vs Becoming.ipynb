{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "narratives = pd.read_csv(\"conversion-narratives/data/website/walkaway_testimonials.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Views</th>\n",
       "      <th>Being</th>\n",
       "      <th>Becoming</th>\n",
       "      <th>postid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trace &amp; Gary's #WalkAway</td>\n",
       "      <td>We don't fall for identity politics. We are a ...</td>\n",
       "      <td>8,996 views</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avialea's #WalkAway</td>\n",
       "      <td>With every rabid attack that the left makes on...</td>\n",
       "      <td>5,850 views</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shane's #WalkAway</td>\n",
       "      <td>I am not your normal republican. I am gay and ...</td>\n",
       "      <td>8,532 views</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sherry's #WalkAway</td>\n",
       "      <td>It is so encouraging to read the stories of pe...</td>\n",
       "      <td>4,085 views</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terri's #WalkAway</td>\n",
       "      <td>I am 66 yrs old and have been a lifelong moder...</td>\n",
       "      <td>4,760 views</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Title  \\\n",
       "0  Trace & Gary's #WalkAway   \n",
       "1       Avialea's #WalkAway   \n",
       "2         Shane's #WalkAway   \n",
       "3        Sherry's #WalkAway   \n",
       "4         Terri's #WalkAway   \n",
       "\n",
       "                                                Body        Views  Being  \\\n",
       "0  We don't fall for identity politics. We are a ...  8,996 views    1.0   \n",
       "1  With every rabid attack that the left makes on...  5,850 views    1.0   \n",
       "2  I am not your normal republican. I am gay and ...  8,532 views    0.0   \n",
       "3  It is so encouraging to read the stories of pe...  4,085 views    0.0   \n",
       "4  I am 66 yrs old and have been a lifelong moder...  4,760 views    0.0   \n",
       "\n",
       "   Becoming  postid  \n",
       "0       0.0       1  \n",
       "1       0.0       2  \n",
       "2       1.0       3  \n",
       "3       1.0       4  \n",
       "4       1.0       5  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narratives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to first load the spacy package\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run all narratives through the spacy parsing \n",
    "narratives['parsed_text'] = list(nlp.pipe(narratives['Body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I nsubj am AUX []\n",
      "am ROOT am AUX [I, not, republican, .]\n",
      "not neg am AUX []\n",
      "your poss republican ADJ []\n",
      "normal amod republican ADJ []\n",
      "republican attr am AUX [your, normal]\n",
      ". punct am AUX []\n",
      "I nsubj am AUX []\n",
      "am ROOT am AUX [I, gay, and, live]\n",
      "gay acomp am AUX []\n",
      "and cc am AUX []\n",
      "I nsubj live VERB []\n",
      "live conj am AUX [I, in, .]\n",
      "in prep live VERB [Tennessee]\n",
      "Tennessee pobj in ADP []\n",
      ". punct live VERB []\n",
      "Throughout prep supported VERB [most]\n",
      "most pobj Throughout ADP [of]\n",
      "of prep most ADJ [life]\n",
      "my poss life NOUN []\n",
      "life pobj of ADP [my]\n",
      "I nsubj supported VERB []\n",
      "supported ROOT supported VERB [Throughout, I, democrats, .]\n",
      "democrats dobj supported VERB [and, left]\n",
      "and cc democrats PROPN []\n",
      "the det left NOUN []\n",
      "left conj democrats PROPN [the]\n",
      ". punct supported VERB []\n",
      "I nsubj thought VERB []\n",
      "thought ROOT thought VERB [I, was]\n",
      "because mark was AUX []\n",
      "I nsubj was AUX []\n",
      "was advcl thought VERB [because, I, gay]\n",
      "gay acomp was AUX []\n",
      "I nsubj had AUX []\n",
      "had ROOT had AUX [I, support, .]\n",
      "to aux support VERB []\n",
      "support xcomp had AUX [to, them]\n",
      "them dobj support VERB []\n",
      ". punct had AUX []\n",
      "I nsubjpass told VERB []\n",
      "was auxpass told VERB []\n",
      "told ROOT told VERB [I, was, were, .]\n",
      "Republicans nsubj were AUX []\n",
      "were ccomp told VERB [Republicans, out, take]\n",
      "out advmod were AUX []\n",
      "to aux take VERB []\n",
      "take advcl were AUX [to, rights, away]\n",
      "my poss rights NOUN []\n",
      "rights dobj take VERB [my]\n",
      "away advmod take VERB []\n",
      ". punct told VERB []\n",
      "I nsubj feared VERB []\n",
      "feared ROOT feared VERB [I, Republicans, from]\n",
      "the det Republicans PROPN []\n",
      "Republicans dobj feared VERB [the]\n",
      "from prep feared VERB [day]\n",
      "the det day NOUN []\n",
      "day pobj from ADP [the, found]\n",
      "I nsubj found VERB []\n",
      "found relcl day NOUN [I, out]\n",
      "out prt found VERB []\n",
      "I nsubj was AUX []\n",
      "was ROOT was AUX [I, gay, .]\n",
      "gay acomp was AUX []\n",
      ". punct was AUX []\n",
      "When advmod was AUX []\n",
      "I nsubj was AUX []\n",
      "was ROOT was AUX [When, I, about]\n",
      "about acomp was AUX [graduate]\n",
      "to aux graduate VERB []\n",
      "graduate xcomp about ADJ [to, school]\n",
      "high amod school NOUN []\n",
      "school dobj graduate VERB [high]\n",
      "I nsubj watched VERB []\n",
      "watched ROOT watched VERB [I, speech, .]\n",
      "Trump poss speech NOUN ['s]\n",
      "'s case Trump PROPN []\n",
      "speech dobj watched VERB [Trump, for]\n",
      "for prep speech NOUN [time]\n",
      "the det time NOUN []\n",
      "first amod time NOUN []\n",
      "time pobj for ADP [the, first]\n",
      ". punct watched VERB []\n",
      "Remember ROOT Remember VERB [was]\n",
      "at prep was AUX [point]\n",
      "this det point NOUN []\n",
      "point pobj at ADP [this]\n",
      "I nsubj was AUX []\n",
      "was ccomp Remember VERB [at, I, support, .]\n",
      "full amod support NOUN []\n",
      "support attr was AUX [full, of]\n",
      "of prep support NOUN [Hillary]\n",
      "Hillary pobj of ADP []\n",
      ". punct was AUX []\n",
      "I nsubj felt VERB []\n",
      "felt ROOT felt VERB [I, something, .]\n",
      "something dobj felt VERB [from]\n",
      "from prep something PRON [said]\n",
      "what dobj said VERB []\n",
      "he nsubj said VERB []\n",
      "said pcomp from ADP [what, he]\n",
      ". punct felt VERB []\n",
      "I nsubj felt VERB []\n",
      "felt ROOT felt VERB [I, safe, for, .]\n",
      "safe acomp felt VERB []\n",
      "for prep felt VERB [time]\n",
      "the det time NOUN []\n",
      "first amod time NOUN []\n",
      "time pobj for ADP [the, first]\n",
      ". punct felt VERB []\n",
      "I nsubj started VERB []\n",
      "then advmod started VERB []\n",
      "started ROOT started VERB [I, then, looking, and, found, .]\n",
      "looking xcomp started VERB [into]\n",
      "into prep looking VERB [party]\n",
      "the det party NOUN []\n",
      "Republican compound party NOUN []\n",
      "party pobj into ADP [the, Republican]\n",
      "and cc started VERB []\n",
      "found conj started VERB [hate]\n",
      "that mark hate VERB []\n",
      "they nsubj hate VERB []\n",
      "do aux hate VERB []\n",
      "n’t neg hate VERB []\n",
      "hate ccomp found VERB [that, they, do, n’t, me]\n",
      "me dobj hate VERB []\n",
      ". punct started VERB []\n",
      "I nsubj found VERB []\n",
      "found ROOT found VERB [I, friends, .]\n",
      "great amod friends NOUN []\n",
      "friends dobj found VERB [great, support]\n",
      "who nsubj support VERB []\n",
      "still advmod support VERB []\n",
      "support relcl friends NOUN [who, still, me, to]\n",
      "me dobj support VERB []\n",
      "to prep support VERB [day]\n",
      "this det day NOUN []\n",
      "day pobj to ADP [this]\n",
      ". punct found VERB []\n",
      "I nsubj voted VERB []\n",
      "voted ROOT voted VERB [I, for, .]\n",
      "for prep voted VERB [Trump]\n",
      "Trump pobj for ADP []\n",
      ". punct voted VERB []\n",
      "For prep see VERB [time]\n",
      "the det time NOUN []\n",
      "first amod time NOUN []\n",
      "time pobj For ADP [the, first, in]\n",
      "in prep time NOUN [life]\n",
      "my poss life NOUN []\n",
      "life pobj in ADP [my]\n",
      "I nsubj see VERB []\n",
      "could aux see VERB []\n",
      "see ROOT see VERB [For, I, could, lies, .]\n",
      "the det lies NOUN []\n",
      "lies dobj see VERB [the, told]\n",
      "that dative told VERB []\n",
      "the det democrats PROPN []\n",
      "democrats nsubj told VERB [the]\n",
      "told relcl lies NOUN [that, democrats, me]\n",
      "me dobj told VERB []\n",
      ". punct see VERB []\n",
      "I nsubj have AUX []\n",
      "do aux have AUX []\n",
      "n’t neg have AUX []\n",
      "have ROOT have AUX [I, do, n’t, vote, ’m, .]\n",
      "to aux vote VERB []\n",
      "vote xcomp have AUX [to, democrat]\n",
      "democrat dobj vote VERB []\n",
      "if mark ’m VERB []\n",
      "I nsubj ’m VERB []\n",
      "’m advcl have AUX [if, I, gay]\n",
      "gay acomp ’m VERB []\n",
      ". punct have AUX []\n",
      "I nsubjpass attacked VERB []\n",
      "was auxpass attacked VERB []\n",
      "attacked ROOT attacked VERB [I, was, by, left, .]\n",
      "by agent attacked VERB [people]\n",
      "people pobj by ADP [on]\n",
      "on prep people NOUN [left]\n",
      "the det left NOUN []\n",
      "left pobj on ADP [the]\n",
      "because mark left VERB []\n",
      "I nsubj left VERB []\n",
      "left advcl attacked VERB [because, I, Party]\n",
      "the det Party PROPN []\n",
      "Democratic compound Party PROPN []\n",
      "Party dobj left VERB [the, Democratic]\n",
      ". punct attacked VERB []\n",
      "This nsubj is AUX []\n",
      "is ROOT is AUX [This, walkaway, .]\n",
      "why advmod walkaway NOUN []\n",
      "I compound walkaway NOUN []\n",
      "# compound walkaway NOUN []\n",
      "walkaway attr is AUX [why, I, #, from]\n",
      "from prep walkaway NOUN [left]\n",
      "the det left NOUN []\n",
      "left pobj from ADP [the]\n",
      ". punct is AUX []\n"
     ]
    }
   ],
   "source": [
    "#example to make sure I know what is going on\n",
    "for tok in narratives['parsed_text'][2]:\n",
    "    print(tok.text, tok.dep_, tok.head.text, tok.head.pos_, [child for child in tok.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERBS IN NARRATIVES\n",
    "verbs = list()\n",
    "tense = list()\n",
    "typ_narr = list()\n",
    "post_id = list()\n",
    "\n",
    "i = 0\n",
    "for doc in narratives['parsed_text']:\n",
    "    for poss_verb in doc:\n",
    "        if poss_verb.pos == spacy.symbols.VERB:\n",
    "            verbs.append(poss_verb)\n",
    "            tense.append(poss_verb.tag_)\n",
    "            post_id.append(narratives['postid'][i])\n",
    "            if narratives['Being'][i] == 1.0:\n",
    "                typ_narr.append(\"Being\")\n",
    "            elif narratives['Becoming'][i] == 1.0:\n",
    "                typ_narr.append(\"Becoming\")\n",
    "            else:\n",
    "                typ_narr.append(\"NA\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_in_texts = pd.DataFrame(\n",
    "                {\"verbs\": verbs,\n",
    "                \"tense\": tense,\n",
    "                \"type_of_narr\": typ_narr,\n",
    "                \"postid\": post_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verbs</th>\n",
       "      <th>tense</th>\n",
       "      <th>type_of_narr</th>\n",
       "      <th>postid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>make</td>\n",
       "      <td>VBP</td>\n",
       "      <td>Being</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>raise</td>\n",
       "      <td>VB</td>\n",
       "      <td>Becoming</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>involves</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>Being</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>made</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Becoming</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>realize</td>\n",
       "      <td>VBP</td>\n",
       "      <td>Becoming</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>bought</td>\n",
       "      <td>VBN</td>\n",
       "      <td>Becoming</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>fit</td>\n",
       "      <td>VB</td>\n",
       "      <td>Becoming</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>voted</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Becoming</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>asked</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Becoming</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>'ll</td>\n",
       "      <td>MD</td>\n",
       "      <td>Becoming</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         verbs tense type_of_narr  postid\n",
       "694       make   VBP        Being      12\n",
       "887      raise    VB     Becoming      17\n",
       "615   involves   VBZ        Being      11\n",
       "155       made   VBD     Becoming       5\n",
       "1648   realize   VBP     Becoming      31\n",
       "131     bought   VBN     Becoming       5\n",
       "855        fit    VB     Becoming      16\n",
       "1347     voted   VBD     Becoming      25\n",
       "906      asked   VBD     Becoming      17\n",
       "1284       'll    MD     Becoming      23"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs_in_texts.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_in_texts.to_csv(\"verbs_in_website.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting nouns\n",
    "noun_phrases = list()\n",
    "post_ids = list()\n",
    "typ_narr = list()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for doc in narratives['parsed_text']:\n",
    "    for phrase in doc.noun_chunks:\n",
    "        noun_phrases.append(phrase)\n",
    "        post_ids.append(narratives['postid'][i])\n",
    "        if narratives['Being'][i] == 1.0:\n",
    "            typ_narr.append(\"Being\")\n",
    "        elif narratives['Becoming'][i] == 1.0:\n",
    "            typ_narr.append(\"Becoming\")\n",
    "        else:\n",
    "            typ_narr.append(\"NA\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_phrases = pd.DataFrame(\n",
    "            {\"noun_phrase\": noun_phrases, \n",
    "             \"postid\": post_ids,\n",
    "            \"type_of_narr\": typ_narr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun_phrase</th>\n",
       "      <th>postid</th>\n",
       "      <th>type_of_narr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(We)</td>\n",
       "      <td>1</td>\n",
       "      <td>Being</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(identity, politics)</td>\n",
       "      <td>1</td>\n",
       "      <td>Being</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(We)</td>\n",
       "      <td>1</td>\n",
       "      <td>Being</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(a, gay, couple)</td>\n",
       "      <td>1</td>\n",
       "      <td>Being</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(who)</td>\n",
       "      <td>1</td>\n",
       "      <td>Being</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            noun_phrase  postid type_of_narr\n",
       "0                  (We)       1        Being\n",
       "1  (identity, politics)       1        Being\n",
       "2                  (We)       1        Being\n",
       "3      (a, gay, couple)       1        Being\n",
       "4                 (who)       1        Being"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_phrases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(I, voted, Dem),\n",
       " (I, explained, None),\n",
       " (He, told, me),\n",
       " (I, did, None),\n",
       " (her, say, None),\n",
       " (I, am, None),\n",
       " (one, tells, me),\n",
       " (I, am, None),\n",
       " (Liars, cheats, None)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def noun_verb_pairs(doc):\n",
    "    nounverbs = list()\n",
    "    for tok in doc:\n",
    "        if tok.dep_ == 'ROOT':\n",
    "            nounverbs.append((child(tok,'nsubj'),tok,child(tok,'dobj')))\n",
    "    return nounverbs\n",
    "\n",
    "def child(tok, dep): # helper function\n",
    "    for c in tok.children:\n",
    "        if c.dep_== dep:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "noun_verb_pairs(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "being = narratives[narratives['Being'] == 1.0]\n",
    "becoming = narratives[narratives['Becoming'] == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "being_nvpairs = list()\n",
    "becoming_nvpairs = list()\n",
    "\n",
    "for doc in being['parsed_text']:\n",
    "    being_nvpairs.append(noun_verb_pairs(doc))\n",
    "\n",
    "for doc in becoming['parsed_text']:\n",
    "    becoming_nvpairs.append(noun_verb_pairs(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "being_nvpairs = pd.DataFrame(\n",
    "    {\"nvpairs\": being_nvpairs,\n",
    "    \"type\": \"Being\"})\n",
    "\n",
    "being_nvpairs = being_nvpairs.explode('nvpairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "becoming_nvpairs = pd.DataFrame(\n",
    "    {\"nvpairs\": becoming_nvpairs,\n",
    "    \"type\": \"Becoming\"})\n",
    "\n",
    "becoming_nvpairs = becoming_nvpairs.explode('nvpairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nvpairs = being_nvpairs.append(becoming_nvpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nvpairs.to_csv(\"web_nvpairs.csv\")\n",
    "noun_phrases.to_csv(\"web_nphrases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
